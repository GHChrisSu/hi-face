---
title: 4.1.2 下篇：图像识别流程——图片裁剪、图片压缩、base64转换
---

知识点

* 成本分析
* 图片压缩的技巧
* base64、buffer等

在《[图片识别加速，从10秒变为1秒，是怎么做到的呢？](tencent-cloud/picture-speed-up-1-second.md)》中，我详细地介绍了我是如何做图片识别加速的。但我这里从上一篇文章的流程与这一篇作对比来简述这件事情。


## 上一篇文章的步骤

<!-- TODO 缺一个时序图 -->

* 选择图片
* 上传原图到云存储，原图通常宽高都大约3000像素，大小约为2M以上，用时2秒左右
* 再获取图片的临时链接，用时1秒左右
* 使用原图进行人脸智能裁剪，获得600x600图片

**实际效果分析**

* 用户选择图片后，会经历3秒左右的等待时间（再加上后面的图像安全审核和五官分析，会更久）
* 原图很大，占据了云存储空间，造成了不必要的浪费。
* 从产品需求角度来说，用户真正需要的是最后的成图，而非原图


## 优化后的步骤

<!-- TODO 缺一个时序图 -->

* 选择图片
* 裁剪图片
* 图片压缩为10%的临时图片
* 临时图片转换为base64数据
* 使用Base64数据进行后续的图像安全审核、人脸五官分析等操作
* 而这之后，可以让用户选择是否将临时图片上传到云存储


### 关于图片裁剪

* 原生小程序用`image-cropper`插件
* Taro中用`taro-cropper`插件

在裁剪图片输出结果时，将图片设置为jpg格式，将图片质量设置为0.8~1之间，此时的图片为裁剪后的原图。

在真正发给云环境进行人脸五官分析的图片是继续使用`wx.compressImage()`为压缩到 10% 质量的的图片。

### 关于图片压缩

在《[图片裁剪、模糊、保存、分享的技巧](../3-knowledge-preparation/3-image-cropper-share.md)》中，我写了关于图片压缩的技巧，其中要点为`wx.compressImage()`的压缩效果不够理想，我还是倾向于看是否能用canvas来压缩图片。

### 将图片转换为base64格式

```js
const fsm = Taro.getFileSystemManager()

let { data: base64Main } = await fsm.readFileSync({
  filePath: resImage.tempFilePath,
  encoding: 'base64',
})
```

一般此时图片会从1.5MB以上变为100KB左右，甚至是70KB

>PS：Base64数据约为Buffer的1.33倍，但感觉还好


### 接下来的内容

图像安全审核是小程序中必不可少的一环，而五官分析也是Hi头像小程序的技术核心，这些都将来后面的文章中详细阐述。

